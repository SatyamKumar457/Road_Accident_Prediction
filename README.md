# ğŸš— Road Accident Severity Prediction  

> **A Machine Learning project to predict road accident severity using regression models**  
> _Developed for Kaggle Playground Series â€“ Season 5, Episode 10_  

---

## ğŸ§¾ Project Metadata (YAML Overview)
```yaml
project:
  name: "Road Accident Severity Prediction"
  author: "Satyam Kumar"
  repository: "https://github.com/SatyamKumar457/Road_Accident_Prediction"
  license: "MIT"
  kaggle_competition: "https://www.kaggle.com/competitions/playground-series-s5e10"
  type: "Supervised Regression"
  target_variable: "Severity"
  language: "Python 3.11"
```

---

## ğŸ¯ Overview  
This project focuses on **predicting road accident severity** using machine learning models trained on environmental, temporal, and road-related factors.  
By analyzing large-scale accident data, the goal is to uncover patterns and build predictive systems that assist in road safety analysis.

---

## ğŸ“Š Dataset Summary
```yaml
dataset:
  source: "Kaggle Playground Series S5E10"
  format: "CSV (train/test)"
  features:
    - ğŸŒ¦ï¸ Weather and visibility
    - ğŸ›£ï¸ Road surface and lighting
    - ğŸš— Vehicle and accident characteristics
    - â±ï¸ Temporal attributes (day, month, time)
  target: "Severity"
```

---

## âš™ï¸ Project Structure
```yaml
structure:
  data:
    - train.csv
    - test.csv
    - sample_submission.csv
  notebooks:
    - Notebook.ipynb
  models:
    - gradient_boosting.pkl
    - random_forest.pkl
    - xgboost.pkl
    - linear_regressor.pkl
    - lgbm_regressor.pkl
    - mlp_regressor.pkl
    - kneighbour.pkl
    - ridge.pkl
    - lasso.pkl
    - elastic_net.pkl
  submissions:
    - submission.csv
    - submission1.csv
    - submission2.csv
  files:
    - LICENSE
    - README.md
```

---

## ğŸ¤– Models and Evaluation  
| ğŸ§  Model | ğŸ¯ RÂ² (Validation) |
|-----------|--------------------|
| **ğŸ“ˆ Linear Regression** | 0.7167 |
| **ğŸŒ² Decision Tree Regressor** | 0.7538 |
| **ğŸŒ² Random Forest Regressor** | 0.8778 |
| **ğŸ”¥ Gradient Boosting Regressor** | 0.8818 |
| **âš¡ XGBoost Regressor** | 0.8848 |
| **LGMB Regressor** | **0.8849** |
| **KNeighbors Regressor** | 0.0846 |
| **MLP Regressor** | 4.422e-06 |
| **Ridge** | 0.7167 |
| **Lasso** | 0.2094 |
| **Elastic Net** | 0.2303 |


> âœ… **Best Model:** LGMB Regressor  
> ğŸ **Leaderboard Score:** `0.05579`  
> ğŸ“Œ Consistent across validation and public board.

---

## ğŸ§  Workflow  
```yaml
workflow:
  - Step 1: Data Cleaning â†’ Handle nulls, encode categories, remove outliers.
  - Step 2: Exploratory Data Analysis â†’ Visualize distributions, correlations.
  - Step 3: Feature Engineering â†’ Time-based, weather, and interaction features.
  - Step 4: Model Training â†’ Ensemble and gradient-based models.
  - Step 5: Evaluation â†’ Metrics: RÂ², RMSE, Kaggle leaderboard.
  - Step 6: Final Submission â†’ Generate predictions and submit CSV.
```

---

## ğŸ“ˆ Results Summary
- ğŸ† **Best Model:** LGMB Regressor   
- ğŸ“Š **Validation RÂ²:** `0.8849`  
- ğŸ’¯ **Leaderboard Score:** `0.05579`  
- ğŸ§© **Rank:** Top consistent performer  
- ğŸ” Improved generalization using **cross-validation** and **early stopping**  

---

## ğŸ§° Tech Stack
```yaml
technologies_used:
  - Python ğŸ
  - Scikit-learn âš™ï¸
  - NumPy / Pandas ğŸ§®
  - Matplotlib / Seaborn ğŸ“Š
  - XGBoost âš¡
  - CatBoost ğŸˆ
  - Kaggle API ğŸ”Œ
```

---

## ğŸ’¡ Future Enhancements
- ğŸ§± Implement model stacking and blending  
- ğŸ§­ Add SHAP/LIME for feature interpretability  
- ğŸ§  Explore deep learning tabular models (TabNet, AutoGluon)  
- ğŸ“Š Build a Streamlit dashboard for interactive visualization  

---

## ğŸ‘¨â€ğŸ’» Author Info
```yaml
author:
  name: "Satyam Kumar"
  github: "https://github.com/SatyamKumar457"
  kaggle: "https://www.kaggle.com/"
  interests: ["AI", "Data Science", "Machine Learning"]
  note: "Exploring ML models that solve real-world safety problems."
```

---

## ğŸ“œ License
This project is licensed under the **MIT License** â€” you are free to use, modify, and distribute with attribution.  

---


